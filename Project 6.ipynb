{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QTgq-IqfEiPT"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# المشروع السادس: هل تستطيع تصنيف النصوص؟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sTvpwwE4EiPV"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "أهلاً بكم في المشروع السادس من علم البيانات. في هذا المشروع، سنقوم معاً بالنظر إلى بيانات فريدة من نوعها وهي مجموعة من النصوص المصنفة إلى مجالات مختلفة. سنقوم بنمذجة هذه البيانات لتوقع تصنيف النصوص بناء على الكلمات الواردة. تستطيع قراءة المزيد عن البيانات من خلال موقع سايكت-ليرن:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WY8p1tTnEiPX"
   },
   "source": [
    "- https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C_7boLBGEiPZ"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "ملاحظة: عليك تعديل الخانات التي يوجد فيها الكود أدناه قبل تسليم المشروع. جميع الخانات الأخرى يجب ان تبقى كما هي بدون أي \n",
    "تعديل.\n",
    "\n",
    "```\n",
    "############################\n",
    "# عليك تعديل هذه الخانة قبل تسليم المشروع\n",
    "# YOU HAVE TO EDIT THIS CELLL\n",
    "############################\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mNvvXHoREiPa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3P12Z3i2EiPg"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# قراءة البيانات"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cWa8IRjhEiPh"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6rrlx1UKEiPp"
   },
   "outputs": [],
   "source": [
    "newsgroups_data = fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "19RcBVzmEiPz"
   },
   "outputs": [],
   "source": [
    "X = newsgroups_data['data']\n",
    "y = newsgroups_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zpWlQk-EEiP3"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "لاحظ أن X هنا عبارة عن قائمة بالنصوص، وليست جدول كما هو الحال مع الدروس الأخرى. أما y فهي كذلك قائمة بالتصنيفات المختلفة. لمعرفة معنى التصنيفات نستطيع طباعة target_names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j_mOkAH1EiP4",
    "outputId": "545f7d80-deca-458f-ed03-129b022c2aeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \t->\t alt.atheism\n",
      "1 \t->\t comp.graphics\n",
      "2 \t->\t comp.os.ms-windows.misc\n",
      "3 \t->\t comp.sys.ibm.pc.hardware\n",
      "4 \t->\t comp.sys.mac.hardware\n",
      "5 \t->\t comp.windows.x\n",
      "6 \t->\t misc.forsale\n",
      "7 \t->\t rec.autos\n",
      "8 \t->\t rec.motorcycles\n",
      "9 \t->\t rec.sport.baseball\n",
      "10 \t->\t rec.sport.hockey\n",
      "11 \t->\t sci.crypt\n",
      "12 \t->\t sci.electronics\n",
      "13 \t->\t sci.med\n",
      "14 \t->\t sci.space\n",
      "15 \t->\t soc.religion.christian\n",
      "16 \t->\t talk.politics.guns\n",
      "17 \t->\t talk.politics.mideast\n",
      "18 \t->\t talk.politics.misc\n",
      "19 \t->\t talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "for i, k in enumerate(newsgroups_data['target_names']):\n",
    "    print(i, '\\t->\\t', k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N817xW7eEiQC"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "وهنا سنقوم بطباعة أول قيمة من X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vSOX9pG6EiQE",
    "outputId": "a19efd5b-7857-4d23-ea28-6b7c634b823b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n",
      "Organization: University of Maryland, College Park\n",
      "Lines: 15\n",
      "\n",
      " I was wondering if anyone out there could enlighten me on this car I saw\n",
      "the other day. It was a 2-door sports car, looked to be from the late 60s/\n",
      "early 70s. It was called a Bricklin. The doors were really small. In addition,\n",
      "the front bumper was separate from the rest of the body. This is \n",
      "all I know. If anyone can tellme a model name, engine specs, years\n",
      "of production, where this car is made, history, or whatever info you\n",
      "have on this funky looking car, please e-mail.\n",
      "\n",
      "Thanks,\n",
      "- IL\n",
      "   ---- brought to you by your neighborhood Lerxst ----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(X[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYsWJy4hEiQI"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "لنقم أولاً بعرض كم عدد النصوص لكل صنف ؟ قد تحتاج لاستخدام باندا للقيام بالمهمة!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rgM7kHnkEiQK",
    "outputId": "fd2d4922-62ea-40c3-c2b7-2834b8c449f3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    600\n",
       "15    599\n",
       "8     598\n",
       "9     597\n",
       "11    595\n",
       "13    594\n",
       "7     594\n",
       "14    593\n",
       "5     593\n",
       "12    591\n",
       "2     591\n",
       "3     590\n",
       "6     585\n",
       "1     584\n",
       "4     578\n",
       "17    564\n",
       "16    546\n",
       "0     480\n",
       "18    465\n",
       "19    377\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############################\n",
    "# عليك تعديل هذه الخانة قبل تسليم المشروع\n",
    "# YOU HAVE TO EDIT THIS CELLL\n",
    "############################\n",
    "\n",
    "df =pd.DataFrame(list(zip(X, y)), columns =['text', 'target']) \n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v0pMf1VLEiQO"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "نرى أن لدينا توازن في توزيع النصوص بين الأصناف المختلفة"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KRx-wLPnEiQQ"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# تجهيز البيانات"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WjUYplPnEiQR"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "ماذا نعمل عادة مع البيانات النصية؟ في هذه الحالة، سيكون أمامنا الكثير لنعمله حتى نقوم بتنظيف هذه البيانات وتهيئتها للتحليل. لذلك سنقوم بكتابة بعض الأوامر التي تساعدنا على ذلك."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sbl2dd7KEiQT"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "المهمة الأولى: تنظيف النص"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4JHzDJ6sEiQU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iOfAkPvAEiQY"
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# عليك تعديل هذه الخانة قبل تسليم المشروع\n",
    "# YOU HAVE TO EDIT THIS CELLL\n",
    "############################\n",
    "\n",
    "\n",
    "# HINT: figure out how to: delete special charachters, delete numbers, delete email addresses\n",
    "#          if you dont know, use google!\n",
    "\n",
    "\n",
    "def clean_text(x):\n",
    "    x = x.lower()\n",
    "    x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "    x = x.encode('ascii', 'ignore').decode()\n",
    "    x = re.sub(r'https*\\S+', ' ', x)\n",
    "    x = re.sub(r'@\\S+', ' ', x)\n",
    "    x = re.sub(r'#\\S+', ' ', x)\n",
    "    x = re.sub(r'\\'\\w+', '', x)\n",
    "    x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "    x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "    x = re.sub(r'\\s{2,}', ' ', x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GgfsB55cEiQd"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "حسنا، سنقوم الآن برؤية أثر هذه التعديلات على العنصر الأول في قائمة النصوص"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pKR3QwGwEiQl",
    "outputId": "0aeec46e-bd71-4edf-d2e7-333c5eaa9641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from lerxst where thing subject car this nntp posting host wam umd edu\n",
      "organization university maryland college park\n",
      "lines wondering anyone could enlighten car saw\n",
      "the day door sports car looked late early called bricklin doors really small addition the front bumper separate rest body all know anyone tellme model name engine specs years\n",
      "of production car made history whatever info you\n",
      "have funky looking car please e mail thanks il brought neighborhood lerxst \n"
     ]
    }
   ],
   "source": [
    "print(clean_text(X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NYPs83ZrEiQq"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "سنقوم الآن بتنفيذ ذات الأمر على باقي النصوص في X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfatLZwnEiQs",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###############\n",
    "data_clean = df.text.apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hfatLZwnEiQs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        from lerxst where thing subject car this nntp ...\n",
      "1        from guykuo guy kuo subject si clock poll fina...\n",
      "2        from twillis thomas e willis subject pb questi...\n",
      "3        from jgreen joe green subject re weitek organi...\n",
      "4        from jcm jonathan mcdowell subject re shuttle ...\n",
      "                               ...                        \n",
      "11309    from jim zisfein jim zisfein subject re migrai...\n",
      "11310    from ebodin subject screen death mac plus line...\n",
      "11311    from westes will estes subject mounting cpu co...\n",
      "11312    from steve steven collins subject re sphere po...\n",
      "11313    from gunning kevin j gunning subject stolen or...\n",
      "Name: text, Length: 11314, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O2BD_ZfeEiQx"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "الآن سنقوم باستخدام Td-IDF لتحويل الكلمات إلى مصفوفة ضخمة حتى نستخدمها في النمذجة. في الخانة التالية، ستقوم باستخدام TfidfVectorizer لتحويل النص."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_XiPxo0EiQz"
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# عليك تعديل هذه الخانة قبل تسليم المشروع\n",
    "# YOU HAVE TO EDIT THIS CELLL\n",
    "############################\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(encoding='utf-8', min_df=.01, max_df=.95)                \n",
    "\n",
    "trn_term_doc = vec.fit_transform(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_4U28AnZEiQ3",
    "outputId": "873154cc-4b3a-469e-b6b2-43878c3af3e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x1977 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 809904 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b6ECk7dREiQ8"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "\n",
    "# نمذجة البيانات"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FANs1n7xEiQ9"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "سنقوم الآن بنمذجة البيانات. لنبدأ بالانحدار اللوجستي. في الخانة أدناه، قم باستيراد كلاً من مكتبة الانحدار اللوجستي، وأمر cross_val_score ثم استخدمهم في تدريب النموذج والتحقق من صحته."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uc6MkCZvEiQ-",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/p1/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/p1/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/p1/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/p1/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/p1/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# عليك تعديل هذه الخانة قبل تسليم المشروع\n",
    "# YOU HAVE TO EDIT THIS CELLL\n",
    "############################\n",
    "\n",
    "# HINT: You should use `train_data` as your input\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "scores = cross_val_score(model, trn_term_doc, df.target, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mlKO_U3YEiRC"
   },
   "outputs": [],
   "source": [
    "avg_score = scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XeEslIT8EiRi",
    "outputId": "d23a74cf-232c-4e4f-aff5-f423781baccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy is:  0.7834553320572795\n"
     ]
    }
   ],
   "source": [
    "print('Average accuracy is: ', avg_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eiypo5UVEiR8"
   },
   "source": [
    "<div style=\"direction:rtl; text-align:right\">\n",
    "لا تحتاج في هذا المشروع إلى تسليم أي ملف إلى كاقل. ولكن تأكد من صحة الإجابات ثم قم بتسليم المشروع في الموقع."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Project 6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
